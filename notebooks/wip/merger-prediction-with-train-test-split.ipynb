{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multicam.mah import get_mah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect MAH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mah_data = get_mah('../../data/processed/bolshoi_m12/', cutoff_missing=0.05, cutoff_particle=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,) (10000,) (10000, 100) (10000, 165) (165,) (100,)\n"
     ]
    }
   ],
   "source": [
    "# catalog\n",
    "cat = mah_data['cat']\n",
    "xoff = cat['x0']\n",
    "cvir = cat['cvir']\n",
    "ma = mah_data['ma']\n",
    "am = mah_data['am']\n",
    "# ma_peak = mah_data['ma_peak']\n",
    "\n",
    "indices = mah_data['indices']\n",
    "scales = mah_data['scales']\n",
    "mass_bins = mah_data['mass_bins']\n",
    "print(cvir.shape, xoff.shape, am.shape, ma.shape, scales.shape, mass_bins.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct indicators and merger ratio at each snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18635   , 0.22919211, 0.27203421, 0.31487632, 0.35771842,\n",
       "       0.40056053, 0.44340263, 0.48624474, 0.52908684, 0.57192895,\n",
       "       0.61477105, 0.65761316, 0.70045526, 0.74329737, 0.78613947,\n",
       "       0.82898158, 0.87182368, 0.91466579, 0.95750789, 1.00035   ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale factor coarser bins \n",
    "min_scale, max_scale = np.min(scales), np.max(scales)\n",
    "scale_bins = np.linspace(min_scale, max_scale, 20)\n",
    "scale_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each simulation scale, get MM \n",
    "# first we need merger ratio at every scale \n",
    "merger_ratio_inst  = np.zeros((len(cat), len(scales)))\n",
    "merger_ratio_present = np.zeros((len(cat), len(scales)))\n",
    "for i in range(len(cat)):\n",
    "    for j, idx in enumerate(indices): \n",
    "        m2_name = f'm2_a{idx}' # TODO: Check what this corresponds to\n",
    "        cpg_name = f'coprog_mvir_a{idx-1}' # want coprogenitor mass at previous timestep.\n",
    "        mvir_name = f'mvir_a{idx}'\n",
    "        \n",
    "        # get inst ratios\n",
    "        m2_ratio = cat[m2_name][i].item() / cat[mvir_name][i].item()\n",
    "        merger_ratio_inst[i, j] = m2_ratio\n",
    "        \n",
    "        # present ratios\n",
    "        m2_ratio = cat[m2_name][i] / cat['mvir'][i].item()\n",
    "        merger_ratio_present[i, j] = m2_ratio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct indicator for each halo whether they have a MM in a given scale bine \n",
    "Mu = [0.3/1.3, 0.1 / 1.1 , 0.03 / (1 + 0.03), 0.01 / 1.01]\n",
    "inst_mask = np.zeros((len(Mu), len(cat), len(scale_bins)-1))\n",
    "present_mask = np.zeros((len(Mu), len(cat), len(scale_bins)-1))\n",
    "\n",
    "# ignore all nanmax warning, these will return np.nan's which is expected. \n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "for kk, mu in enumerate(Mu):\n",
    "    for jj in range(len(scale_bins) - 1):\n",
    "        # get largest merger ratio in this scale bin\n",
    "        mask = (scales >= scale_bins[jj]) & (scales < scale_bins[jj+1])\n",
    "        inst_mask[kk, :, jj] = np.nanmax(merger_ratio_inst[:, mask], axis=1) > mu\n",
    "        present_mask[kk, :, jj] = np.nanmax(merger_ratio_present[:, mask], axis=1) > mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use coarser bins for merger bins like in the 'merger residuals' plots\n",
    "\n",
    "x1 = ma\n",
    "\n",
    "mask2 = np.isnan(merger_ratio_inst)\n",
    "x2 = np.where(mask2, 0, merger_ratio_inst)\n",
    "\n",
    "# use scale_bins instead of scales, take max over mergers in each bin.\n",
    "x3 = np.zeros((x2.shape[0], scale_bins.shape[0]))\n",
    "for ii, scale in enumerate(scales):\n",
    "    jj = np.where(scale >= scale_bins)[0][-1]\n",
    "    arr = np.vstack([x3[:, jj], x2[:, ii]])\n",
    "    assert arr.shape == (2, 10000)\n",
    "    x3[:, jj] = np.max(arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = np.concatenate([x1, x2], axis=1)\n",
    "\n",
    "y = np.concatenate([cat['cvir'][:, None], cat['x0'][:, None], cat['t/|u|'][:, None], \n",
    "                    cat['spin_bullock'][:, None], cat['c_to_a'][:,None]], \n",
    "                    axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multicam.models import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train standard MultiCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = LinearRegression(165, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.fit(x_train[:, :165], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.641537189483643, 5.6473517417907715)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.predict(x_test[:,:165])[4, 0], mc.predict(x_test[4, None, :165])[0,0] # almost the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008627065044904316"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean cvir and mean predicted cvir for sanity check\n",
    "cvir_mean = np.mean(y_test[:, 0])\n",
    "cvir_pred_mean = np.mean(mc.predict(x_test[:,:165])[:,0])\n",
    "np.abs(cvir_mean - cvir_pred_mean) / np.abs(cvir_mean) # very low error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with coarse merger ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_merger = LinearRegression(330, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_merger.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = mc.predict(x_test[:,:165])\n",
    "y_pred2 = mc_merger.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7852376886380997 0.6919254816649411\n"
     ]
    }
   ],
   "source": [
    "from multicam.correlations import spearmanr\n",
    "\n",
    "spearmans1 = spearmanr(y_test[:, 0], y_pred1[:, 0])\n",
    "spearmans2 = spearmanr(y_test[:, 0], y_pred2[:, 0])\n",
    "\n",
    "print(spearmans1, spearmans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbody-relaxed-P7T5KfjX-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
