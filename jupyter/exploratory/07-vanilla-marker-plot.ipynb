{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "# %reload_ext autoreload\n",
    "\n",
    "import sys \n",
    "from os.path import abspath\n",
    "paths = [abspath('../..'), \"/home/imendoza/alcca/nbody-relaxed/packages/minnow\"]\n",
    "\n",
    "for path in paths: \n",
    "    if path not in sys.path: \n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import re \n",
    "from astropy.table import Table\n",
    "import astropy.table\n",
    "\n",
    "from relaxed import utils \n",
    "from relaxed.frames import params, catalogs, filters\n",
    "from relaxed.progenitors import progenitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load catalogs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load catalog we know and love (kindof)\n",
    "# produced by --summary option from a /bin file \n",
    "prog_table_file = '/home/imendoza/alcca/nbody-relaxed/data/trees_bolshoi/progenitors.csv'\n",
    "cat_filepath = Path('/home/imendoza/alcca/nbody-relaxed/data/Bolshoi/'\n",
    "                    'minh/hlist_1.00035.minh')\n",
    "name = 'BolshoiP'\n",
    "hcat = catalogs.HaloCatalog(cat_filepath, name, verbose=True, add_subhalo=True, add_progenitor=prog_table_file)\n",
    "hcat.load_base_cat()\n",
    "cat = hcat._cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare additional catalogs, all are of course automatically loaded when created in this way\n",
    "colors = ['r','b', 'g']\n",
    "\n",
    "print('total: ', len(hcat))\n",
    "\n",
    "log_func = lambda x: np.log10(x)\n",
    "hcat_m11 = catalogs.HaloCatalog.create_filtered_from_base(hcat, \n",
    "                                                          filters.get_bound_filter('mvir',high=11.22, modifier=log_func), \n",
    "                                                          label=\"M11\")\n",
    "hcat_m12 = catalogs.HaloCatalog.create_filtered_from_base(hcat, \n",
    "                                                          filters.get_bound_filter('mvir',12,12.2, modifier=log_func),\n",
    "                                                          label=\"M12\")\n",
    "hcat_m13 = catalogs.HaloCatalog.create_filtered_from_base(hcat, \n",
    "                                                          filters.get_bound_filter('mvir',13, 14, modifier=log_func),\n",
    "                                                          label=\"M13\")\n",
    "\n",
    "print(len(hcat_m11), len(hcat_m12), len(hcat_m13))\n",
    "# 500 haloes are so > 13.75 \n",
    "\n",
    "power_cat = catalogs.HaloCatalog.create_relaxed_from_base(hcat, 'power2011')\n",
    "neto_cat = catalogs.HaloCatalog.create_relaxed_from_base(hcat, 'neto2007')\n",
    "print(len(power_cat), len(neto_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids1 = set(hcat_m11._cat['id'])\n",
    "ids2 = set(hcat_m12._cat['id'])\n",
    "ids3 = set(hcat_m13._cat['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save progenitors in sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import ascii\n",
    "prog_file = '/home/imendoza/alcca/nbody-relaxed/data/trees_bolshoi/progenitors.txt'\n",
    "prog_generator = progenitors.get_prog_lines_generator(prog_file)\n",
    "# there are like 382474 main lines (in the filtered version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_progenitor_path = Path('/home/imendoza/alcca/nbody-relaxed/data/trees_bolshoi/progenitor_subset2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, prog in enumerate(prog_generator): \n",
    "    if i % 10000 == 0: \n",
    "        print(i)\n",
    "    if prog.root_id in ids1: \n",
    "        path = new_progenitor_path.joinpath(f\"{int(prog.root_id)}.csv\")\n",
    "        ascii.write(prog.cat, path, format='fast_csv', fast_writer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# how long just load each of them \n",
    "for i, f in enumerate(new_progenitor_path.iterdir()):\n",
    "#     print(f)\n",
    "    t = Table.read(f, format='ascii.fast_csv')\n",
    "    if i %1000 == 0: \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import csv\n",
    "\n",
    "# TODO: add root_id to everything and root_halo_mvir\n",
    "\n",
    "z_map = {}\n",
    "count = 0\n",
    "z_dir = new_progenitor_path.joinpath(\"z_files\")\n",
    "z_map_file = z_dir.joinpath(\"z_map.json\")\n",
    "z_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(new_progenitor_path.iterdir()): \n",
    "    if f.suffix == '.csv':\n",
    "        if i%1000 ==0: \n",
    "            print(i)\n",
    "\n",
    "        prog_cat = Table.read(f, format='ascii.fast_csv')\n",
    "        root_id = prog_cat[0]['halo_id']\n",
    "\n",
    "        assert max(prog_cat['scale']) == prog_cat['scale'][0], \"make sure order is correct\"\n",
    "\n",
    "        for row in prog_cat: \n",
    "            a, mvir = row['scale'], row['mvir']\n",
    "\n",
    "            if a not in z_map: \n",
    "                z_map[a] = count \n",
    "                count+=1 \n",
    "            z_file = z_dir.joinpath(f\"{z_map[a]}.csv\")\n",
    "\n",
    "\n",
    "            fieldnames = ['root_id', 'mvir']\n",
    "\n",
    "            if not z_file.exists(): \n",
    "                with open(z_file, 'w') as zf: \n",
    "                    writer = csv.DictWriter(zf, fieldnames)\n",
    "                    writer.writeheader()\n",
    "            with open(z_file, 'a') as zf: \n",
    "                writer = csv.DictWriter(zf, fieldnames)\n",
    "                dct = {'root_id': root_id, 'mvir': mvir}\n",
    "                writer.writerow(dct)\n",
    "                zf.flush()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save json file for z_map\n",
    "# import json \n",
    "# with open(z_map_file, 'w') as fp: \n",
    "#     json.dump(z_map, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "with open(z_map_file, 'r') as zf: \n",
    "    z_map = json.load(zf)\n",
    "    \n",
    "inv_z_map = {v:k for k,v in z_map.items()}\n",
    "\n",
    "cat = hcat_m11.get_cat()\n",
    "cat.sort('id')\n",
    "\n",
    "scales = [] \n",
    "corrs = [] \n",
    "n_halos = [] \n",
    "\n",
    "z_files = np.sort([int(p.stem) for p in z_dir.iterdir() if p.suffix=='.csv'])\n",
    "z_files = [z_dir.joinpath(str(name)+'.csv') for name in z_files]\n",
    "\n",
    "for f in z_files:\n",
    "    scale_key = int(f.stem)\n",
    "    scale = float(inv_z_map[scale_key])\n",
    "    scales.append(scale)\n",
    "\n",
    "    t = Table.read(f, format='ascii.fast_csv')\n",
    "    t.sort('root_id')\n",
    "    t.rename_column('root_id', 'id')\n",
    "\n",
    "    _cat = catalogs.intersection(cat, t)\n",
    "    t = catalogs.intersection(t, _cat)\n",
    "    \n",
    "    n_halos.append(len(t))\n",
    "\n",
    "    corr = spearmanr(t['mvir']/_cat['mvir'], _cat['cvir'])\n",
    "    corrs.append(corr.correlation)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scales, corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
